import pandas as pd
import numpy as np
from unidecode import unidecode
import re
from typing import List, Dict, Tuple, Optional
import colorsys
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from difflib import SequenceMatcher
import warnings
warnings.filterwarnings('ignore')

class DuplicateDetector:
    def __init__(self, similarity_threshold: float = 0.70):
        """
        Ð”ÐµÑ‚ÐµÐºÑ‚Ð¾Ñ€ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ñ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð°Ñ†Ð¸ÐµÐ¹ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ð¼ÐµÑ‚Ð¾Ð´Ð¾Ð²
        
        Args:
            similarity_threshold: Ð¿Ð¾Ñ€Ð¾Ð³ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð¾Ñ‚ 0 Ð´Ð¾ 1 (Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ 0.70)
        """
        self.similarity_threshold = similarity_threshold
        self.vectorizer = None
        
        # Ð ÐµÐ³ÑƒÐ»ÑÑ€Ð½Ñ‹Ðµ Ð²Ñ‹Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð´Ð»Ñ Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¹ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        self.patterns = {
            'extra_spaces': r'\s+',
            'punctuation': r'[^\w\s]',
            'numbers_only': r'^\d+$',
            'org_forms': r'\b(Ð¾Ð¾Ð¾|Ð¾Ð°Ð¾|Ð·Ð°Ð¾|Ð¸Ð¿|Ñ‚Ð¾Ð²|ltd|llc|inc|corp|co)\b',
        }

    def generate_colors(self, num_colors: int, is_dark_theme: bool = False) -> List[str]:
        """Ð“ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ñ Ñ†Ð²ÐµÑ‚Ð¾Ð² Ð´Ð»Ñ Ð³Ñ€ÑƒÐ¿Ð¿ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²"""
        colors = []
        for i in range(num_colors):
            hue = i / num_colors
            
            if is_dark_theme:
                saturation = 0.6 + (i % 3) * 0.1
                lightness = 0.4 + (i % 4) * 0.1
            else:
                saturation = 0.4 + (i % 3) * 0.1
                lightness = 0.85 + (i % 3) * 0.05
            
            rgb = colorsys.hls_to_rgb(hue, lightness, saturation)
            hex_color = "#{:02x}{:02x}{:02x}".format(int(rgb[0]*255), int(rgb[1]*255), int(rgb[2]*255))
            colors.append(hex_color)
        return colors

    def normalize_text(self, text: str) -> str:
        """Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð°"""
        if pd.isna(text) or not text:
            return ""
        
        text = str(text).strip().lower()
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹ Ð¸ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÑŽ
        text = re.sub(self.patterns['punctuation'], ' ', text)
        text = re.sub(self.patterns['extra_spaces'], ' ', text).strip()
        
        return text

    def normalize_text_strict(self, text: str) -> str:
        """Ð¡Ñ‚Ñ€Ð¾Ð³Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ñ‚ÐµÐºÑÑ‚Ð° Ð´Ð»Ñ Ð±Ð¾Ð»ÐµÐµ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð³Ð¾ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ"""
        if pd.isna(text) or not text:
            return ""
        
        text = str(text).strip().lower()
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ñ‹
        text = re.sub(self.patterns['org_forms'], '', text, flags=re.IGNORECASE)
        
        # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÑŽ Ð¸ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹
        text = re.sub(self.patterns['punctuation'], ' ', text)
        text = re.sub(self.patterns['extra_spaces'], ' ', text).strip()
        
        # Ð¢Ñ€Ð°Ð½ÑÐ»Ð¸Ñ‚ÐµÑ€Ð°Ñ†Ð¸Ñ Ð´Ð»Ñ ÐºÐ¸Ñ€Ð¸Ð»Ð»Ð¸Ñ†Ñ‹
        try:
            text = unidecode(text)
        except:
            pass
        
        return text

    def string_similarity(self, str1: str, str2: str) -> float:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ ÑÑ‚Ñ€Ð¾Ðº Ñ‡ÐµÑ€ÐµÐ· SequenceMatcher"""
        if not str1 or not str2:
            return 0.0
        return SequenceMatcher(None, str1, str2).ratio()

    def jaccard_similarity(self, str1: str, str2: str) -> float:
        """Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸ Ð–Ð°ÐºÐºÐ°Ñ€Ð° Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ ÑÐ»Ð¾Ð²"""
        if not str1 or not str2:
            return 0.0
        
        set1 = set(str1.split())
        set2 = set(str2.split())
        
        intersection = set1.intersection(set2)
        union = set1.union(set2)
        
        if not union:
            return 0.0
        
        return len(intersection) / len(union)

    def calculate_combined_similarity(self, text1: str, text2: str) -> float:
        """ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ðµ Ð²Ñ‹Ñ‡Ð¸ÑÐ»ÐµÐ½Ð¸Ðµ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸"""
        if not text1 or not text2:
            return 0.0
        
        # Ð‘Ð°Ð·Ð¾Ð²Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        norm1 = self.normalize_text(text1)
        norm2 = self.normalize_text(text2)
        
        # Ð¡Ñ‚Ñ€Ð¾Ð³Ð°Ñ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        strict1 = self.normalize_text_strict(text1)
        strict2 = self.normalize_text_strict(text2)
        
        # Ð Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸
        basic_sim = self.string_similarity(norm1, norm2)
        strict_sim = self.string_similarity(strict1, strict2)
        jaccard_sim = self.jaccard_similarity(norm1, norm2)
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð° Ñ‚Ð¾Ñ‡Ð½Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð¿Ð¾ÑÐ»Ðµ Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸
        if strict1 == strict2 and len(strict1) > 2:
            return 1.0
        
        # ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð¾Ñ†ÐµÐ½ÐºÐ° Ñ Ð²ÐµÑÐ°Ð¼Ð¸
        combined_score = (basic_sim * 0.4 + strict_sim * 0.4 + jaccard_sim * 0.2)
        
        return combined_score

    def find_duplicates(self, df: pd.DataFrame, name_column: str, address_column: Optional[str] = None, id_column: Optional[str] = None) -> Tuple[List[List[int]], Dict]:
        """
        ÐŸÐ¾Ð¸ÑÐº Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð² Ñ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ð½Ð¸ÐµÐ¼ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼Ð°
        
        Args:
            df: DataFrame Ñ Ð´Ð°Ð½Ð½Ñ‹Ð¼Ð¸
            name_column: ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸
            address_column: ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° Ñ Ð°Ð´Ñ€ÐµÑÐ°Ð¼Ð¸ (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾)
            id_column: ÐºÐ¾Ð»Ð¾Ð½ÐºÐ° Ñ ID (Ð¾Ð¿Ñ†Ð¸Ð¾Ð½Ð°Ð»ÑŒÐ½Ð¾, Ð½Ðµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÑ‚ÑÑ)
            
        Returns:
            (Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð², ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÐ°)
        """
        if df.empty:
            return [], {'total_records': 0, 'duplicate_groups': 0, 'duplicate_records': 0, 'unique_records': 0}
        
        # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ ÐºÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ñ‚ÐµÐºÑÑ‚Ñ‹ Ð´Ð»Ñ ÑÑ€Ð°Ð²Ð½ÐµÐ½Ð¸Ñ
        combined_texts = []
        for idx, row in df.iterrows():
            name_text = str(row[name_column]) if pd.notna(row[name_column]) else ""
            address_text = ""
            
            if address_column and address_column in df.columns and pd.notna(row[address_column]):
                address_text = str(row[address_column])
            
            # ÐžÐ±ÑŠÐµÐ´Ð¸Ð½ÑÐµÐ¼ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ðµ Ð¸ Ð°Ð´Ñ€ÐµÑ
            combined_text = f"{name_text} {address_text}".strip()
            combined_texts.append(combined_text)
        
        # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð³Ñ€ÑƒÐ¿Ð¿Ñ‹ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²
        duplicate_groups = []
        processed_indices = set()
        
        for i in range(len(combined_texts)):
            if i in processed_indices:
                continue
            
            current_group = [i]
            
            for j in range(i + 1, len(combined_texts)):
                if j in processed_indices:
                    continue
                
                # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ
                similarity = self.calculate_combined_similarity(combined_texts[i], combined_texts[j])
                
                # Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð´Ð»Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ð¹
                name_similarity = self.calculate_combined_similarity(
                    str(df.iloc[i][name_column]) if pd.notna(df.iloc[i][name_column]) else "",
                    str(df.iloc[j][name_column]) if pd.notna(df.iloc[j][name_column]) else ""
                )
                
                # Ð¡Ñ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð°Ð¼Ð¸ ÐµÑÐ»Ð¸:
                # 1. ÐžÐ±Ñ‰Ð°Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð²Ñ‹ÑˆÐµ Ð¿Ð¾Ñ€Ð¾Ð³Ð° Ð˜Ð›Ð˜
                # 2. Ð¡Ñ…Ð¾Ð¶ÐµÑÑ‚ÑŒ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ð¹ Ð¾Ñ‡ÐµÐ½ÑŒ Ð²Ñ‹ÑÐ¾ÐºÐ°Ñ (>0.8)
                if similarity >= self.similarity_threshold or name_similarity >= 0.8:
                    current_group.append(j)
            
            if len(current_group) > 1:
                duplicate_groups.append(current_group)
                processed_indices.update(current_group)
        
        # Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÐ¼ ÑÑ‚Ð°Ñ‚Ð¸ÑÑ‚Ð¸ÐºÑƒ
        stats = {
            'total_records': len(df),
            'duplicate_groups': len(duplicate_groups),
            'duplicate_records': sum(len(group) for group in duplicate_groups),
            'unique_records': len(df) - sum(len(group) for group in duplicate_groups)
        }
        
        return duplicate_groups, stats

    def create_grouped_dataframe(self, df: pd.DataFrame, duplicate_groups: List[List[int]]) -> pd.DataFrame:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ DataFrame Ñ Ð³Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€Ð¾Ð²ÐºÐ¾Ð¹ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²"""
        if not duplicate_groups:
            result_df = df.copy()
            result_df['Duplicate_Group'] = 0
            return result_df
        
        grouped_data = []
        group_counter = 1
        
        for group in duplicate_groups:
            for row_idx in group:
                row_data = df.iloc[row_idx].to_dict()
                row_data['Duplicate_Group'] = group_counter
                grouped_data.append(row_data)
            group_counter += 1
        
        # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ðµ Ð·Ð°Ð¿Ð¸ÑÐ¸
        remaining_indices = set(range(len(df))) - set(idx for group in duplicate_groups for idx in group)
        for row_idx in remaining_indices:
            row_data = df.iloc[row_idx].to_dict()
            row_data['Duplicate_Group'] = 0
            grouped_data.append(row_data)
        
        result_df = pd.DataFrame(grouped_data)
        result_df = result_df.sort_values(['Duplicate_Group', result_df.columns[0]], ascending=[False, True])
        
        return result_df

    def create_styled_dataframe(self, df: pd.DataFrame, duplicate_groups: List[List[int]], is_dark_theme: bool = False) -> Dict:
        """Ð¡Ð¾Ð·Ð´Ð°Ð½Ð¸Ðµ ÑÑ‚Ð¸Ð»Ð¸Ð·Ð¾Ð²Ð°Ð½Ð½Ð¾Ð³Ð¾ DataFrame Ð´Ð»Ñ Ð¾Ñ‚Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ"""
        grouped_df = self.create_grouped_dataframe(df, duplicate_groups)
        
        if not duplicate_groups:
            return {
                "data": grouped_df.values.tolist(),
                "headers": grouped_df.columns.tolist(),
                "metadata": {"styling": []},
            }
        
        colors = self.generate_colors(len(duplicate_groups), is_dark_theme)
        
        styling = []
        for _ in range(len(grouped_df)):
            styling.append([""] * len(grouped_df.columns))
        
        for idx, row in grouped_df.iterrows():
            group_num = row['Duplicate_Group']
            if group_num > 0:
                color = colors[(group_num - 1) % len(colors)]
                for col_idx in range(len(grouped_df.columns)):
                    styling[idx][col_idx] = f"background-color: {color};"
        
        return {
            "data": grouped_df.values.tolist(),
            "headers": grouped_df.columns.tolist(),
            "metadata": {
                "styling": styling,
            },
        }

    def find_name_column(self, df: pd.DataFrame) -> Optional[str]:
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸/Ð½Ð°Ð¸Ð¼ÐµÐ½Ð¾Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸"""
        columns = [col.lower() for col in df.columns]
        
        # ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ñ‹Ðµ ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸ÑÐ¼Ð¸
        name_keywords = [
            'Ð½Ð°Ð·Ð²Ð°Ð½', 'Ð½Ð°Ð¸Ð¼ÐµÐ½', 'Ð¸Ð¼Ñ', 'name', 'title', 'ÐºÐ¾Ð¼Ð¿Ð°Ð½', 'Ð¾Ñ€Ð³Ð°Ð½Ð¸Ð·Ð°Ñ†', 
            'Ð¿Ñ€ÐµÐ´Ð¿Ñ€Ð¸ÑÑ‚', 'Ñ„Ð¸Ñ€Ð¼', 'company', 'organization', 'firm'
        ]
        
        for i, col in enumerate(columns):
            for keyword in name_keywords:
                if keyword in col:
                    return df.columns[i]
        
        return None
    
    def find_address_column(self, df: pd.DataFrame) -> Optional[str]:
        """ÐÐ²Ñ‚Ð¾Ð¼Ð°Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸ Ð½Ð°Ñ…Ð¾Ð´Ð¸Ñ‚ ÐºÐ¾Ð»Ð¾Ð½ÐºÑƒ Ñ Ð°Ð´Ñ€ÐµÑÐ°Ð¼Ð¸"""
        columns = [col.lower() for col in df.columns]
        
        # ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð° Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ° ÐºÐ¾Ð»Ð¾Ð½ÐºÐ¸ Ñ Ð°Ð´Ñ€ÐµÑÐ°Ð¼Ð¸
        address_keywords = ['Ð°Ð´Ñ€ÐµÑ', 'address', 'Ð¼ÐµÑÑ‚Ð¾Ð¿Ð¾Ð»Ð¾Ð¶ÐµÐ½', 'location']
        
        for i, col in enumerate(columns):
            for keyword in address_keywords:
                if keyword in col:
                    return df.columns[i]
        
        return None

    def get_similarity_info(self) -> str:
        """ÐŸÐ¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¾ Ð¼ÐµÑ‚Ð¾Ð´Ðµ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸"""
        return f"""
        ðŸ”¬ **ÐœÐµÑ‚Ð¾Ð´ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð´ÑƒÐ±Ð»Ð¸ÐºÐ°Ñ‚Ð¾Ð²:**
        - ÐšÐ¾Ð¼Ð±Ð¸Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ Ð°Ð»Ð³Ð¾Ñ€Ð¸Ñ‚Ð¼
        - Ð¡Ñ…Ð¾Ð¶ÐµÑÑ‚ÑŒ ÑÑ‚Ñ€Ð¾Ðº + Ð–Ð°ÐºÐºÐ°Ñ€ + Ð½Ð¾Ñ€Ð¼Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ
        - ÐŸÐ¾Ñ€Ð¾Ð³ ÑÑ…Ð¾Ð¶ÐµÑÑ‚Ð¸: {self.similarity_threshold:.2f}
        - Ð”Ð¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ð¹ (>0.8)
        """ 