import pandas as pd
import numpy as np
from unidecode import unidecode
import re
from typing import List, Dict, Tuple, Optional
import colorsys
from difflib import SequenceMatcher
import warnings

warnings.filterwarnings("ignore")


class DuplicateDetector:
    def __init__(self, similarity_threshold: float = 0.80):
        self.similarity_threshold = similarity_threshold
        self.vectorizer = None

        # –†–µ–≥—É–ª—è—Ä–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        self.patterns = {
            "extra_spaces": r"\s+",
            "punctuation": r"[^\w\s\d]",
            "org_forms": r"\b(–æ–æ–æ|–æ–∞–æ|–∑–∞–æ|–∏–ø|—Ç–æ–≤|ltd|llc|inc|corp|co|–æ–±—â–µ—Å—Ç–≤–æ|–ø—Ä–µ–¥–ø—Ä–∏—è—Ç–∏–µ)\b",
            "address_numbers": r"\b\d+[\/\-]?\d*\b",  # –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤, –∫–≤–∞—Ä—Ç–∏—Ä
            "postal_codes": r"\b\d{5,6}\b",  # –ø–æ—á—Ç–æ–≤—ã–µ –∏–Ω–¥–µ–∫—Å—ã
        }

    def generate_colors(
        self, num_colors: int, is_dark_theme: bool = False
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ü–≤–µ—Ç–æ–≤ –¥–ª—è –≥—Ä—É–ø–ø –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        colors = []
        for i in range(num_colors):
            hue = i / num_colors

            if is_dark_theme:
                saturation = 0.6 + (i % 3) * 0.1
                lightness = 0.4 + (i % 4) * 0.1
            else:
                saturation = 0.4 + (i % 3) * 0.1
                lightness = 0.85 + (i % 3) * 0.05

            rgb = colorsys.hls_to_rgb(hue, lightness, saturation)
            hex_color = "#{:02x}{:02x}{:02x}".format(
                int(rgb[0] * 255), int(rgb[1] * 255), int(rgb[2] * 255)
            )
            colors.append(hex_color)
        return colors

    def normalize_text(self, text: str, preserve_numbers: bool = True) -> str:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞

        Args:
            text: –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç
            preserve_numbers: —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —á–∏—Å–ª–∞ (–≤–∞–∂–Ω–æ –¥–ª—è –∞–¥—Ä–µ—Å–æ–≤)
        """
        if pd.isna(text) or not text:
            return ""

        text = str(text).strip().lower()

        # –£–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ–∫—Ä–∏—Ç–∏—á–Ω—É—é –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é, —Å–æ—Ö—Ä–∞–Ω—è—è —á–∏—Å–ª–∞ –∏ –≤–∞–∂–Ω—ã–µ —Å–∏–º–≤–æ–ª—ã
        if preserve_numbers:
            text = re.sub(r'[,.\-‚Ññ"\'()]', " ", text)
        else:
            text = re.sub(self.patterns["punctuation"], " ", text)

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(self.patterns["extra_spaces"], " ", text).strip()

        return text

    def normalize_name(self, name: str) -> str:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π"""
        if pd.isna(name) or not name:
            return ""

        name = str(name).strip().lower()

        # –£–±–∏—Ä–∞–µ–º –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—ã
        name = re.sub(self.patterns["org_forms"], "", name, flags=re.IGNORECASE)

        # –£–±–∏—Ä–∞–µ–º –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é
        name = re.sub(r"[^\w\s]", " ", name)
        name = re.sub(self.patterns["extra_spaces"], " ", name).strip()

        return name

    def extract_address_numbers(self, address: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤ –∏–∑ –∞–¥—Ä–µ—Å–∞"""
        if pd.isna(address) or not address:
            return []

        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∏—Å–ª–∞ –≤ –∞–¥—Ä–µ—Å–µ (–Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤, –∫–≤–∞—Ä—Ç–∏—Ä –∏ —Ç.–¥.)
        numbers = re.findall(self.patterns["address_numbers"], str(address))
        return numbers

    def string_similarity(self, str1: str, str2: str) -> float:
        """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Å—Ö–æ–∂–µ—Å—Ç–∏ —Å—Ç—Ä–æ–∫ —á–µ—Ä–µ–∑ SequenceMatcher"""
        if not str1 or not str2:
            return 0.0
        return SequenceMatcher(None, str1, str2).ratio()

    def name_similarity(self, name1: str, name2: str) -> float:
        """–°–ø–µ—Ü–∏–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π"""
        if not name1 or not name2:
            return 0.0

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è
        norm1 = self.normalize_name(name1)
        norm2 = self.normalize_name(name2)

        # –¢–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –ø–æ—Å–ª–µ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
        if norm1 == norm2 and len(norm1) > 2:
            return 1.0

        # –ë–∞–∑–æ–≤–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å
        basic_sim = self.string_similarity(norm1, norm2)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ–¥–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥—Ä—É–≥–æ–µ
        if norm1 in norm2 or norm2 in norm1:
            return max(basic_sim, 0.9)

        return basic_sim

    def address_similarity(self, addr1: str, addr2: str) -> float:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏ –∞–¥—Ä–µ—Å–æ–≤ —Å —É—á–µ—Ç–æ–º –Ω–æ–º–µ—Ä–æ–≤ –¥–æ–º–æ–≤"""
        if not addr1 or not addr2:
            return 0.0

        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∞–¥—Ä–µ—Å–∞
        norm1 = self.normalize_text(addr1, preserve_numbers=True)
        norm2 = self.normalize_text(addr2, preserve_numbers=True)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤
        numbers1 = self.extract_address_numbers(addr1)
        numbers2 = self.extract_address_numbers(addr2)

        # –ï—Å–ª–∏ —É –æ–±–æ–∏—Ö –∞–¥—Ä–µ—Å–æ–≤ –µ—Å—Ç—å –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤ –∏ –æ–Ω–∏ —Ä–∞–∑–Ω—ã–µ, —Ç–æ –∞–¥—Ä–µ—Å–∞ —Ç–æ—á–Ω–æ —Ä–∞–∑–Ω—ã–µ
        if numbers1 and numbers2:
            common_numbers = set(numbers1).intersection(set(numbers2))
            if not common_numbers:
                return 0.0  # –†–∞–∑–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤ = —Ä–∞–∑–Ω—ã–µ –∞–¥—Ä–µ—Å–∞

        # –ë–∞–∑–æ–≤–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –∞–¥—Ä–µ—Å–æ–≤
        basic_sim = self.string_similarity(norm1, norm2)

        # –ï—Å–ª–∏ –æ–¥–∏–Ω –∞–¥—Ä–µ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–æ–º–µ—Ä –¥–æ–º–∞, –∞ –¥—Ä—É–≥–æ–π –Ω–µ—Ç, —Ç–æ —Å–Ω–∏–∂–∞–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å
        if (numbers1 and not numbers2) or (numbers2 and not numbers1):
            basic_sim *= 0.8  # –°–Ω–∏–∂–∞–µ–º –Ω–∞ 20%

        return basic_sim

    def are_duplicates(
        self,
        row1: pd.Series,
        row2: pd.Series,
        name_col: str,
        address_col: Optional[str] = None,
    ) -> bool:
        """
        –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤

        Args:
            row1, row2: —Å—Ç—Ä–æ–∫–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            name_col: –∫–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
            address_col: –∫–æ–ª–æ–Ω–∫–∞ —Å –∞–¥—Ä–µ—Å–∞–º–∏

        Returns:
            True –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ —è–≤–ª—è—é—Ç—Å—è –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
        """
        name1 = str(row1[name_col]) if pd.notna(row1[name_col]) else ""
        name2 = str(row2[name_col]) if pd.notna(row2[name_col]) else ""

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ö–æ–∂–µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π
        name_sim = self.name_similarity(name1, name2)

        # –ï—Å–ª–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –æ—á–µ–Ω—å —Ä–∞–∑–Ω—ã–µ, —Ç–æ —ç—Ç–æ —Ç–æ—á–Ω–æ –Ω–µ –¥—É–±–ª–∏–∫–∞—Ç—ã
        if name_sim < 0.6:
            return False

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∞–¥—Ä–µ—Å–∞, –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö
        if address_col and address_col in row1.index and address_col in row2.index:
            addr1 = str(row1[address_col]) if pd.notna(row1[address_col]) else ""
            addr2 = str(row2[address_col]) if pd.notna(row2[address_col]) else ""

            addr_sim = self.address_similarity(addr1, addr2)

            # –ï—Å–ª–∏ –∞–¥—Ä–µ—Å–∞ –æ—á–µ–Ω—å —Ä–∞–∑–Ω—ã–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Ä–∞–∑–Ω—ã–µ –Ω–æ–º–µ—Ä–∞ –¥–æ–º–æ–≤), —Ç–æ –ù–ï –¥—É–±–ª–∏–∫–∞—Ç—ã
            if addr_sim == 0.0:
                return False

            # –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ —Å –±–æ–ª–µ–µ –º—è–≥–∫–∏–º–∏ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º–∏
            combined_sim = name_sim * 0.7 + addr_sim * 0.3

            # –£—Å–ª–æ–≤–∏—è –¥–ª—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:
            # 1. –û—á–µ–Ω—å –≤—ã—Å–æ–∫–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π (>0.85) –ò–õ–ò
            # 2. –•–æ—Ä–æ—à–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–π (>0.7) –ò —Ö–æ—Ä–æ—à–∞—è —Å—Ö–æ–∂–µ—Å—Ç—å –∞–¥—Ä–µ—Å–æ–≤ (>0.7) –ò–õ–ò
            # 3. –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ >0.75
            return (
                name_sim >= 0.85
                or (name_sim >= 0.7 and addr_sim >= 0.7)
                or combined_sim >= 0.75
            )
        else:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∞–¥—Ä–µ—Å–æ–≤, —Ç–æ –Ω–∞–∑–≤–∞–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–º–∏
            return name_sim >= 0.85

    def find_duplicates(
        self,
        df: pd.DataFrame,
        name_column: str,
        address_column: Optional[str] = None,
        id_column: Optional[str] = None,
    ) -> Tuple[List[List[int]], Dict]:
        """
        –ü–æ–∏—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –ª–æ–≥–∏–∫–æ–π

        Args:
            df: DataFrame —Å –¥–∞–Ω–Ω—ã–º–∏
            name_column: –∫–æ–ª–æ–Ω–∫–∞ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
            address_column: –∫–æ–ª–æ–Ω–∫–∞ —Å –∞–¥—Ä–µ—Å–∞–º–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            id_column: –∫–æ–ª–æ–Ω–∫–∞ —Å ID (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è)

        Returns:
            (–≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞)
        """
        if df.empty:
            return [], {
                "total_records": 0,
                "duplicate_groups": 0,
                "duplicate_records": 0,
                "unique_records": 0,
            }

        # –ù–∞—Ö–æ–¥–∏–º –≥—Ä—É–ø–ø—ã –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
        duplicate_groups = []
        processed_indices = set()

        for i in range(len(df)):
            if i in processed_indices:
                continue

            current_group = [i]

            for j in range(i + 1, len(df)):
                if j in processed_indices:
                    continue

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –∑–∞–ø–∏—Å–∏ –¥—É–±–ª–∏–∫–∞—Ç–∞–º–∏
                if self.are_duplicates(
                    df.iloc[i], df.iloc[j], name_column, address_column
                ):
                    current_group.append(j)

            if len(current_group) > 1:
                duplicate_groups.append(current_group)
                processed_indices.update(current_group)

        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = {
            "total_records": len(df),
            "duplicate_groups": len(duplicate_groups),
            "duplicate_records": sum(len(group) for group in duplicate_groups),
            "unique_records": len(df) - sum(len(group) for group in duplicate_groups),
        }

        return duplicate_groups, stats

    def create_grouped_dataframe(
        self, df: pd.DataFrame, duplicate_groups: List[List[int]]
    ) -> pd.DataFrame:
        """–°–æ–∑–¥–∞–Ω–∏–µ DataFrame —Å –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–æ–π –¥—É–±–ª–∏–∫–∞—Ç–æ–≤"""
        if not duplicate_groups:
            result_df = df.copy()
            result_df["Duplicate_Group"] = 0
            return result_df

        grouped_data = []
        group_counter = 1

        for group in duplicate_groups:
            for row_idx in group:
                row_data = df.iloc[row_idx].to_dict()
                row_data["Duplicate_Group"] = group_counter
                grouped_data.append(row_data)
            group_counter += 1

        # –î–æ–±–∞–≤–ª—è–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–∞–ø–∏—Å–∏
        remaining_indices = set(range(len(df))) - set(
            idx for group in duplicate_groups for idx in group
        )
        for row_idx in remaining_indices:
            row_data = df.iloc[row_idx].to_dict()
            row_data["Duplicate_Group"] = 0
            grouped_data.append(row_data)

        result_df = pd.DataFrame(grouped_data)
        result_df = result_df.sort_values(
            ["Duplicate_Group", result_df.columns[0]], ascending=[False, True]
        )

        return result_df

    def create_styled_dataframe(
        self,
        df: pd.DataFrame,
        duplicate_groups: List[List[int]],
        is_dark_theme: bool = False,
    ) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–≥–æ DataFrame –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        grouped_df = self.create_grouped_dataframe(df, duplicate_groups)

        if not duplicate_groups:
            return {
                "data": grouped_df.values.tolist(),
                "headers": grouped_df.columns.tolist(),
                "metadata": {"styling": []},
            }

        colors = self.generate_colors(len(duplicate_groups), is_dark_theme)

        styling = []
        for _ in range(len(grouped_df)):
            styling.append([""] * len(grouped_df.columns))

        for idx, row in grouped_df.iterrows():
            group_num = row["Duplicate_Group"]
            if group_num > 0:
                color = colors[(group_num - 1) % len(colors)]
                for col_idx in range(len(grouped_df.columns)):
                    styling[idx][col_idx] = f"background-color: {color};"

        return {
            "data": grouped_df.values.tolist(),
            "headers": grouped_df.columns.tolist(),
            "metadata": {
                "styling": styling,
            },
        }

    def find_name_column(self, df: pd.DataFrame) -> Optional[str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫—É —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏/–Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏—è–º–∏"""
        columns = [col.lower() for col in df.columns]

        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        name_keywords = [
            "–Ω–∞–∑–≤–∞–Ω",
            "–Ω–∞–∏–º–µ–Ω",
            "–∏–º—è",
            "name",
            "title",
            "–∫–æ–º–ø–∞–Ω",
            "–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü",
            "–ø—Ä–µ–¥–ø—Ä–∏—è—Ç",
            "—Ñ–∏—Ä–º",
            "company",
            "organization",
            "firm",
        ]

        for i, col in enumerate(columns):
            for keyword in name_keywords:
                if keyword in col:
                    return df.columns[i]

        return None

    def find_address_column(self, df: pd.DataFrame) -> Optional[str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞—Ö–æ–¥–∏—Ç –∫–æ–ª–æ–Ω–∫—É —Å –∞–¥—Ä–µ—Å–∞–º–∏"""
        columns = [col.lower() for col in df.columns]

        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–ª–æ–Ω–∫–∏ —Å –∞–¥—Ä–µ—Å–∞–º–∏
        address_keywords = ["–∞–¥—Ä–µ—Å", "address", "–º–µ—Å—Ç–æ–ø–æ–ª–æ–∂–µ–Ω", "location"]

        for i, col in enumerate(columns):
            for keyword in address_keywords:
                if keyword in col:
                    return df.columns[i]

        return None

    def get_similarity_info(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–µ—Ç–æ–¥–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ö–æ–∂–µ—Å—Ç–∏"""
        return f"""
        üî¨ **–ú–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥—É–±–ª–∏–∫–∞—Ç–æ–≤:**
        - –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π –∞–¥—Ä–µ—Å–æ–≤
        - –£—á–µ—Ç –Ω–æ–º–µ—Ä–æ–≤ –¥–æ–º–æ–≤ –∏ —Ä–∞–∑–ª–∏—á–∏–π –≤ –∞–¥—Ä–µ—Å–∞—Ö
        - –°—Ç—Ä–æ–≥–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å—Ö–æ–∂–µ—Å—Ç–∏ –Ω–∞–∑–≤–∞–Ω–∏–π (>80%)
        - –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—Ü–µ–Ω–∫–∞: –Ω–∞–∑–≤–∞–Ω–∏–µ + –∞–¥—Ä–µ—Å
        """
